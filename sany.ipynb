{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from utils import configuration\r\n",
    "from utils.utils import set_seeds\r\n",
    "import trainer\r\n",
    "from load_data import load_data\r\n",
    "\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn as nn\r\n",
    "import torch\r\n",
    "\r\n",
    "from transformers import (\r\n",
    "    AutoConfig,\r\n",
    "    AutoModelForSequenceClassification,\r\n",
    ")\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cfg = 'config/uda.json'\r\n",
    "model_cfg = 'config/bert_base.json'\r\n",
    "cfg = configuration.params.from_json(cfg)\r\n",
    "model_cfg = configuration.model.from_json(model_cfg)\r\n",
    "set_seeds(cfg.seed)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load Data & Create Criterion\r\n",
    "data = load_data(cfg)\r\n",
    "if cfg.uda_mode:\r\n",
    "    unsup_criterion = nn.KLDivLoss(reduction='none')\r\n",
    "    data_iter = [data.sup_data_iter(), data.unsup_data_iter()] if cfg.mode == 'train' \\\r\n",
    "        else [data.sup_data_iter(), data.unsup_data_iter(), data.eval_data_iter()]  # train_eval\r\n",
    "else:\r\n",
    "    raise NotImplemented\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Load model\r\n",
    "config = AutoConfig.from_pretrained(\r\n",
    "    model_cfg.model_name_or_path,\r\n",
    "    num_labels=model_cfg.num_labels\r\n",
    ")\r\n",
    "\r\n",
    "model = AutoModelForSequenceClassification.from_config(config=config)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# train\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "device = torch.device('cuda')\r\n",
    "\r\n",
    "# model을 gpu에 올린다.\r\n",
    "#model = model.to(device)\r\n",
    "model = AutoModelForSequenceClassification.from_config(config=config)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "## 학습\r\n",
    "# loss 기록\r\n",
    "losses = []\r\n",
    "\r\n",
    "# 학습 시작\r\n",
    "for step, batch in enumerate(data_iter[0]):\r\n",
    "    # 텐서로 바꿔준다. 데이터 종류에 따른  dtype을 다르게 한다\r\n",
    "    #input_ids, input_mask, input_type_ids, labels = [t.to(device) for t in batch]\r\n",
    "    input_ids, input_mask, input_type_ids, labels = batch\r\n",
    "    outputs = model(input_ids, input_mask, input_type_ids)    \r\n",
    "    loss = criterion(outputs.logits, labels)\r\n",
    "    #print(loss.dtype)\r\n",
    "    losses.append(loss)\r\n",
    "\r\n",
    "    # backpropagation\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    # logging\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# 학습 시작\r\n",
    "losses = []\r\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\r\n",
    "for step, batch in enumerate(data_iter[1]):\r\n",
    "    # 텐서로 바꿔준다. 데이터 종류에 따른  dtype을 다르게 한다\r\n",
    "    if step == 2:\r\n",
    "        break\r\n",
    "    #ori_input_ids, ori_input_mask, ori_input_type_ids, \\\r\n",
    "    #aug_input_ids, aug_input_mask, aug_input_type_ids = [t.to(device) for t in batch]\r\n",
    "    ori_input_ids, ori_input_mask, ori_input_type_ids, \\\r\n",
    "    aug_input_ids, aug_input_mask, aug_input_type_ids = batch\r\n",
    "    ori_outputs = model(ori_input_ids, ori_input_mask, ori_input_type_ids)\r\n",
    "    aug_outputs = model(aug_input_ids, aug_input_mask, aug_input_type_ids)   \r\n",
    "    print(ori_outputs.logits)\r\n",
    "    print(torch.argmax(ori_outputs.logits, dim=1))\r\n",
    "    print(torch.argmax(aug_outputs.logits, dim=1))\r\n",
    "    loss = criterion(ori_outputs.logits, aug_outputs.logits)\r\n",
    "    print(loss)\r\n",
    "    losses.append(loss)\r\n",
    "\r\n",
    "    # backpropagation\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    # logging\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.1113, -0.2415],\n",
      "        [-0.1140,  0.0909],\n",
      "        [-0.2046, -0.1474],\n",
      "        [-0.5358, -0.2203],\n",
      "        [-0.2453, -0.3304],\n",
      "        [-0.0010, -0.3264]], grad_fn=<AddmmBackward>)\n",
      "tensor([0, 1, 1, 1, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "tensor(0., grad_fn=<DivBackward0>)\n",
      "tensor([[-0.1298,  0.0715],\n",
      "        [-0.5477, -0.1378],\n",
      "        [-0.2407,  0.0166],\n",
      "        [-0.5359, -0.1954],\n",
      "        [-0.3624, -0.1927],\n",
      "        [-0.3526, -0.1333]], grad_fn=<AddmmBackward>)\n",
      "tensor([1, 1, 1, 1, 1, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1])\n",
      "tensor(-0.0559, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model save\r\n",
    "\r\n",
    "# model load"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('uda': conda)"
  },
  "interpreter": {
   "hash": "c83a7510ad18b29dfa5117131711e2c63bed04f56a8aa80dd1a92ae7b310bfb3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}